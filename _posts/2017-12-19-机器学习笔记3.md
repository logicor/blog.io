#神经网络综述



<h2 id="11-non-linear-hypotheses"><a name="t1"></a>1.1 Non-linear hypotheses</h2>

<p>在coursa课程的开头，提到了非线性假设，会因为特征量的增多导致二次项数的剧增。 <br>
举个例子，在图像识别中，一个50*50像素的图片，拥有的特征量为2500，那么它的二次项数为2500*2500/2,大约为3百万个。</p>



<h2 id="12-model-representation"><a name="t2"></a>1.2 Model representation</h2>

<p><img src="https://img-blog.csdn.net/20170501171249892?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
上层是一个三层神经网络，第一层为输入层，第二层为隐藏层，第三层为输出层。 <br>
每条边上有一个权值<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B8;</mi></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 0.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.469em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.43em, 1000.46em, 2.458em, -1000em); top: -2.292em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3" style="font-family: MathJax_Math; font-style: italic;">θ</span></span><span style="display: inline-block; width: 0px; height: 2.292em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.074em; border-left: 0px solid; width: 0px; height: 0.983em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><script type="math/tex" id="MathJax-Element-1">\theta</script></p>

<p>下面是符号表示。 <br>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msubsup><mi>a</mi><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>j</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4" style="width: 1.773em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.458em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.98em, 1001.46em, 2.654em, -1000em); top: -2.188em; left: 0em;"><span class="mrow" id="MathJax-Span-5"><span class="msubsup" id="MathJax-Span-6"><span style="display: inline-block; position: relative; width: 1.445em; height: 0px;"><span style="position: absolute; clip: rect(3.413em, 1000.51em, 4.177em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-7" style="font-family: MathJax_Math; font-style: italic;">a</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(3.324em, 1000.92em, 4.343em, -1000em); top: -4.532em; left: 0.529em;"><span class="texatom" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mo" id="MathJax-Span-10" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-11" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">j</span><span class="mo" id="MathJax-Span-12" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(3.387em, 1000.32em, 4.174em, -1000em); top: -3.707em; left: 0.529em;"><span class="mi" id="MathJax-Span-13" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.188em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.435em; border-left: 0px solid; width: 0px; height: 1.76em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>a</mi><mi>i</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup></math></span></span><script type="math/tex" id="MathJax-Element-2">a^{(j)}_i</script>：第j层单元i的“激励” <br>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>&amp;#x03B8;</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>j</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-14" style="width: 1.721em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.406em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.138em, 1001.41em, 2.354em, -1000em); top: -2.188em; left: 0em;"><span class="mrow" id="MathJax-Span-15"><span class="msubsup" id="MathJax-Span-16"><span style="display: inline-block; position: relative; width: 1.385em; height: 0px;"><span style="position: absolute; clip: rect(3.149em, 1000.46em, 4.177em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-17" style="font-family: MathJax_Math; font-style: italic;">θ</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.373em; left: 0.469em;"><span class="texatom" id="MathJax-Span-18"><span class="mrow" id="MathJax-Span-19"><span class="mo" id="MathJax-Span-20" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-21" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">j</span><span class="mo" id="MathJax-Span-22" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.188em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.074em; border-left: 0px solid; width: 0px; height: 1.209em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>θ</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-3">\theta^{(j)}</script>：第j层到第j+1层单元的权值矩阵。 <br>
若第j层单元数为<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mi>j</mi></msub></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-23" style="width: 1.044em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.833em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.589em, 1000.83em, 2.638em, -1000em); top: -2.188em; left: 0em;"><span class="mrow" id="MathJax-Span-24"><span class="msubsup" id="MathJax-Span-25"><span style="display: inline-block; position: relative; width: 0.835em; height: 0px;"><span style="position: absolute; clip: rect(3.412em, 1000.42em, 4.177em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-26" style="font-family: MathJax_Math; font-style: italic;">s</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -3.86em; left: 0.469em;"><span class="mi" id="MathJax-Span-27" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">j</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.188em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.416em; border-left: 0px solid; width: 0px; height: 1.008em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mi>j</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-4">s_j</script>，第j+1层单元数为<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-28" style="width: 2.086em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.719em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.589em, 1001.72em, 2.638em, -1000em); top: -2.188em; left: 0em;"><span class="mrow" id="MathJax-Span-29"><span class="msubsup" id="MathJax-Span-30"><span style="display: inline-block; position: relative; width: 1.739em; height: 0px;"><span style="position: absolute; clip: rect(3.412em, 1000.42em, 4.177em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-31" style="font-family: MathJax_Math; font-style: italic;">s</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -3.86em; left: 0.469em;"><span class="texatom" id="MathJax-Span-32"><span class="mrow" id="MathJax-Span-33"><span class="mi" id="MathJax-Span-34" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">j</span><span class="mo" id="MathJax-Span-35" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mn" id="MathJax-Span-36" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.188em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.416em; border-left: 0px solid; width: 0px; height: 1.008em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5">s_{j+1}</script>，则<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>&amp;#x03B8;</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>j</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mi>&amp;#x03F5;</mi><msup><mi>R</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>s</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>&amp;#x2217;</mo><mo stretchy=&quot;false&quot;>(</mo><msub><mi>s</mi><mi>j</mi></msub><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-37" style="width: 7.503em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.25em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.242em, 1006.25em, 2.469em, -1000em); top: -2.292em; left: 0em;"><span class="mrow" id="MathJax-Span-38"><span class="msubsup" id="MathJax-Span-39"><span style="display: inline-block; position: relative; width: 1.385em; height: 0px;"><span style="position: absolute; clip: rect(3.149em, 1000.46em, 4.177em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-40" style="font-family: MathJax_Math; font-style: italic;">θ</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.373em; left: 0.469em;"><span class="texatom" id="MathJax-Span-41"><span class="mrow" id="MathJax-Span-42"><span class="mo" id="MathJax-Span-43" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-44" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">j</span><span class="mo" id="MathJax-Span-45" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mi" id="MathJax-Span-46" style="font-family: MathJax_Math; font-style: italic;">ϵ</span><span class="msubsup" id="MathJax-Span-47"><span style="display: inline-block; position: relative; width: 4.462em; height: 0px;"><span style="position: absolute; clip: rect(3.171em, 1000.76em, 4.188em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-48" style="font-family: MathJax_Math; font-style: italic;">R</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.373em; left: 0.759em;"><span class="texatom" id="MathJax-Span-49"><span class="mrow" id="MathJax-Span-50"><span class="msubsup" id="MathJax-Span-51"><span style="display: inline-block; position: relative; width: 1.23em; height: 0px;"><span style="position: absolute; clip: rect(3.542em, 1000.3em, 4.174em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-52" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">s</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -3.904em; left: 0.332em;"><span class="texatom" id="MathJax-Span-53"><span class="mrow" id="MathJax-Span-54"><span class="mi" id="MathJax-Span-55" style="font-size: 50%; font-family: MathJax_Math; font-style: italic;">j</span><span class="mo" id="MathJax-Span-56" style="font-size: 50%; font-family: MathJax_Main;">+</span><span class="mn" id="MathJax-Span-57" style="font-size: 50%; font-family: MathJax_Main;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-58" style="font-size: 70.7%; font-family: MathJax_Main;">∗</span><span class="mo" id="MathJax-Span-59" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-60"><span style="display: inline-block; position: relative; width: 0.591em; height: 0px;"><span style="position: absolute; clip: rect(3.542em, 1000.3em, 4.174em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-61" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">s</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -3.904em; left: 0.332em;"><span class="mi" id="MathJax-Span-62" style="font-size: 50%; font-family: MathJax_Math; font-style: italic;">j</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-63" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mn" id="MathJax-Span-64" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-65" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.292em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.088em; border-left: 0px solid; width: 0px; height: 1.222em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>θ</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msup><mi>ϵ</mi><msup><mi>R</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>s</mi><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∗</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mi>j</mi></msub><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-6">\theta^{(j)}\epsilon R^{s_{j+1}*(s_j+1)}</script>。（记住第j层有一个偏置单元）。 <br>
<img src="https://img-blog.csdn.net/20170501172859575?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
在bp神经网络中，我们使用sigmoid函数作为激励函数。即<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style="position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mi>z</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mi>z</mi></mrow></msup></mrow></mfrac></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-66" style="width: 6.409em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.313em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.257em, 1005.31em, 2.909em, -1000em); top: -2.292em; left: 0em;"><span class="mrow" id="MathJax-Span-67"><span class="mi" id="MathJax-Span-68" style="font-family: MathJax_Math; font-style: italic;">g<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-69" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-70" style="font-family: MathJax_Math; font-style: italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-71" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-72" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mfrac" id="MathJax-Span-73" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 2.029em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.383em, 1000.3em, 4.167em, -1000em); top: -4.418em; left: 50%; margin-left: -0.177em;"><span class="mn" id="MathJax-Span-74" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(3.358em, 1001.91em, 4.225em, -1000em); top: -3.607em; left: 50%; margin-left: -0.955em;"><span class="mrow" id="MathJax-Span-75"><span class="mn" id="MathJax-Span-76" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-77" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="msubsup" id="MathJax-Span-78"><span style="display: inline-block; position: relative; width: 1.006em; height: 0px;"><span style="position: absolute; clip: rect(3.542em, 1000.3em, 4.174em, -1000em); top: -4.01em; left: 0em;"><span class="mi" id="MathJax-Span-79" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">e</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.215em; left: 0.33em;"><span class="texatom" id="MathJax-Span-80"><span class="mrow" id="MathJax-Span-81"><span class="mo" id="MathJax-Span-82" style="font-size: 50%; font-family: MathJax_Main;">−</span><span class="mi" id="MathJax-Span-83" style="font-size: 50%; font-family: MathJax_Math; font-style: italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(0.82em, 1002.03em, 1.198em, -1000em); top: -1.262em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.029em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.042em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.292em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.616em; border-left: 0px solid; width: 0px; height: 1.733em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>g</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-7">g(z) = \frac{1}{1+e^{-z}}</script>，也就是我们逻辑回归中使用的函数。</p>



<h2 id="13-examples-and-intuitions"><a name="t3"></a>1.3 Examples and intuitions</h2>

<p><img src="https://img-blog.csdn.net/20170501173806265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
通过构造一个2层神经网络我们实现了and逻辑。</p>

<p><img src="https://img-blog.csdn.net/20170501174032887?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
通过构造一个2层神经网络我们实现了and逻辑。</p>

<p><img src="https://img-blog.csdn.net/20170501180201497?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
我们通过组合的方式将and notand 和or逻辑组合在一起构造一个三层神经网络完成X XNOR Y 逻辑。</p>



<h2 id="14-multi-class-classification"><a name="t4"></a>1.4 Multi-class classification</h2>

<p>对于多分类问题，我们可以通过设置多个输出值来实现。 <br>
<img src="https://img-blog.csdn.net/20170501181352733?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
具体在程序中，可以通过每个输出值 取最大值来判断属于哪一类。</p>

<h2 id="14-作业代码"><a name="t5"></a>1.4 作业代码</h2>

<p>这次的作业是用逻辑回归和神经网络来实现手写数字识别，比较下两者的准确性。</p>

<p>ex3.m</p>



<pre class="prettyprint"><code class="language-matlab hljs  has-numbering"><span class="hljs-comment">%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all</span>

<span class="hljs-comment">%  Instructions</span>
<span class="hljs-comment">%  ------------</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%  This file contains code that helps you get started on the</span>
<span class="hljs-comment">%  linear exercise. You will need to complete the following functions</span>
<span class="hljs-comment">%  in this exericse:</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%     lrCostFunction.m (logistic regression cost function)</span>
<span class="hljs-comment">%     oneVsAll.m</span>
<span class="hljs-comment">%     predictOneVsAll.m</span>
<span class="hljs-comment">%     predict.m</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%  For this exercise, you will not need to change any code in this file,</span>
<span class="hljs-comment">%  or any other files other than those mentioned above.</span>
<span class="hljs-comment">%</span>

<span class="hljs-comment">%% Initialization</span>
clear ; close all; clc

<span class="hljs-comment">%% Setup the parameters you will use for this part of the exercise</span>
input_layer_size  = <span class="hljs-number">400</span>;  <span class="hljs-comment">% 20x20 Input Images of Digits</span>
num_labels = <span class="hljs-number">10</span>;          <span class="hljs-comment">% 10 labels, from 1 to 10</span>
                          <span class="hljs-comment">% (note that we have mapped "0" to label 10)</span>

<span class="hljs-comment">%% =========== Part 1: Loading and Visualizing Data =============</span>
<span class="hljs-comment">%  We start the exercise by first loading and visualizing the dataset.</span>
<span class="hljs-comment">%  You will be working with a dataset that contains handwritten digits.</span>
<span class="hljs-comment">%</span>

<span class="hljs-comment">% Load Training Data</span>
fprintf(<span class="hljs-string">'Loading and Visualizing Data ...\n'</span>)

load(<span class="hljs-string">'ex3data1.mat'</span>); <span class="hljs-comment">% training data stored in arrays X, y</span>
m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);

<span class="hljs-comment">% Randomly select 100 data points to display</span>
rand_indices = randperm(m);
sel = X(rand_indices(<span class="hljs-number">1</span>:<span class="hljs-number">100</span>), :);

displayData(sel);

fprintf(<span class="hljs-string">'Program paused. Press enter to continue.\n'</span>);
pause;

<span class="hljs-comment">%% ============ Part 2a: Vectorize Logistic Regression ============</span>
<span class="hljs-comment">%  In this part of the exercise, you will reuse your logistic regression</span>
<span class="hljs-comment">%  code from the last exercise. You task here is to make sure that your</span>
<span class="hljs-comment">%  regularized logistic regression implementation is vectorized. After</span>
<span class="hljs-comment">%  that, you will implement one-vs-all classification for the handwritten</span>
<span class="hljs-comment">%  digit dataset.</span>
<span class="hljs-comment">%</span>

<span class="hljs-comment">% Test case for lrCostFunction</span>
fprintf(<span class="hljs-string">'\nTesting lrCostFunction() with regularization'</span>);

theta_t = <span class="hljs-matrix">[-<span class="hljs-number">2</span>; -<span class="hljs-number">1</span>; <span class="hljs-number">1</span>; <span class="hljs-number">2</span>]</span>;
X_t = <span class="hljs-matrix">[ones(<span class="hljs-number">5</span>,<span class="hljs-number">1</span>) reshape(<span class="hljs-number">1</span>:<span class="hljs-number">15</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>)/<span class="hljs-number">10</span>]</span>;
y_t = (<span class="hljs-matrix">[<span class="hljs-number">1</span>;<span class="hljs-number">0</span>;<span class="hljs-number">1</span>;<span class="hljs-number">0</span>;<span class="hljs-number">1</span>]</span> &gt;= <span class="hljs-number">0.5</span>);
lambda_t = <span class="hljs-number">3</span>;
<span class="hljs-matrix">[J grad]</span> = lrCostFunction(theta_t, X_t, y_t, lambda_t);

fprintf(<span class="hljs-string">'\nCost: %f\n'</span>, J);
fprintf(<span class="hljs-string">'Expected cost: 2.534819\n'</span>);
fprintf(<span class="hljs-string">'Gradients:\n'</span>);
fprintf(<span class="hljs-string">' %f \n'</span>, grad);
fprintf(<span class="hljs-string">'Expected gradients:\n'</span>);
fprintf(<span class="hljs-string">' 0.146561\n -0.548558\n 0.724722\n 1.398003\n'</span>);

fprintf(<span class="hljs-string">'Program paused. Press enter to continue.\n'</span>);
pause;
<span class="hljs-comment">%% ============ Part 2b: One-vs-All Training ============</span>
fprintf(<span class="hljs-string">'\nTraining One-vs-All Logistic Regression...\n'</span>)

lambda = <span class="hljs-number">0.1</span>;
<span class="hljs-matrix">[all_theta]</span> = oneVsAll(X, y, num_labels, lambda);

fprintf(<span class="hljs-string">'Program paused. Press enter to continue.\n'</span>);
pause;


<span class="hljs-comment">%% ================ Part 3: Predict for One-Vs-All ================</span>

pred = predictOneVsAll(all_theta, X);

fprintf(<span class="hljs-string">'\nTraining Set Accuracy: %f\n'</span>, mean(double(pred == y)) * <span class="hljs-number">100</span>);
</code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li style="color: rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li style="color: rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li style="color: rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li style="color: rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li style="color: rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li style="color: rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, 153);">73</li><li style="color: rgb(153, 153, 153);">74</li><li style="color: rgb(153, 153, 153);">75</li><li style="color: rgb(153, 153, 153);">76</li><li style="color: rgb(153, 153, 153);">77</li><li style="color: rgb(153, 153, 153);">78</li><li style="color: rgb(153, 153, 153);">79</li><li style="color: rgb(153, 153, 153);">80</li><li style="color: rgb(153, 153, 153);">81</li><li style="color: rgb(153, 153, 153);">82</li><li style="color: rgb(153, 153, 153);">83</li><li style="color: rgb(153, 153, 153);">84</li><li style="color: rgb(153, 153, 153);">85</li><li style="color: rgb(153, 153, 153);">86</li><li style="color: rgb(153, 153, 153);">87</li><li style="color: rgb(153, 153, 153);">88</li></ul></pre>

<p>lrCostFunction.m</p>



<pre class="prettyprint"><code class="language-matlab hljs  has-numbering"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[J, grad]</span> = <span class="hljs-title">lrCostFunction</span><span class="hljs-params">(theta, X, y, lambda)</span></span>
<span class="hljs-comment">%LRCOSTFUNCTION Compute cost and gradient for logistic regression with </span>
<span class="hljs-comment">%regularization</span>
<span class="hljs-comment">%   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using</span>
<span class="hljs-comment">%   theta as the parameter for regularized logistic regression and the</span>
<span class="hljs-comment">%   gradient of the cost w.r.t. to the parameters. </span>

<span class="hljs-comment">% Initialize some useful values</span>
m = <span class="hljs-built_in">length</span>(y); <span class="hljs-comment">% number of training examples</span>

<span class="hljs-comment">% You need to return the following variables correctly </span>
J = <span class="hljs-number">0</span>;
grad = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(theta));

<span class="hljs-comment">% ====================== YOUR CODE HERE ======================</span>
<span class="hljs-comment">% Instructions: Compute the cost of a particular choice of theta.</span>
<span class="hljs-comment">%               You should set J to the cost.</span>
<span class="hljs-comment">%               Compute the partial derivatives and set grad to the partial</span>
<span class="hljs-comment">%               derivatives of the cost w.r.t. each parameter in theta</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Hint: The computation of the cost function and gradients can be</span>
<span class="hljs-comment">%       efficiently vectorized. For example, consider the computation</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%           sigmoid(X * theta)</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%       Each row of the resulting matrix will contain the value of the</span>
<span class="hljs-comment">%       prediction for that example. You can make use of this to vectorize</span>
<span class="hljs-comment">%       the cost function and gradient computations. </span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Hint: When computing the gradient of the regularized cost function, </span>
<span class="hljs-comment">%       there're many possible vectorized solutions, but one solution</span>
<span class="hljs-comment">%       looks like:</span>
<span class="hljs-comment">%           grad = (unregularized gradient for logistic regression)</span>
<span class="hljs-comment">%           temp = theta; </span>
<span class="hljs-comment">%           temp(1) = 0;   % because we don't add anything for j = 0  </span>
<span class="hljs-comment">%           grad = grad + YOUR_CODE_HERE (using the temp variable)</span>
<span class="hljs-comment">%</span>

J = <span class="hljs-number">1</span>/m * (-<span class="hljs-transposed_variable">y'</span> * <span class="hljs-built_in">log</span>(sigmoid(X*theta)) - (<span class="hljs-number">1</span> - <span class="hljs-transposed_variable">y'</span>)* <span class="hljs-built_in">log</span>(<span class="hljs-number">1</span>-sigmoid(X*theta))) + lambda/<span class="hljs-number">2</span>/m*sum(theta(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>) .^ <span class="hljs-number">2</span>);

grad(<span class="hljs-number">1</span>, :) = <span class="hljs-number">1</span>/m * (X(:,<span class="hljs-number">1</span>)<span class="hljs-string">'* (sigmoid(X*theta) - y));
grad(2:end, :) = 1/m * (X(:,2:end)'</span>* (sigmoid(X*theta) - y)) + lambda/m*theta(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>, :);
<span class="hljs-comment">% =============================================================</span>

grad = grad(:);

<span class="hljs-keyword">end</span>
</code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li></ul></pre>

<p>oneVsAll.m</p>



<pre class="prettyprint"><code class="language-matlab hljs  has-numbering"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[all_theta]</span> = <span class="hljs-title">oneVsAll</span><span class="hljs-params">(X, y, num_labels, lambda)</span></span>
<span class="hljs-comment">%ONEVSALL trains multiple logistic regression classifiers and returns all</span>
<span class="hljs-comment">%the classifiers in a matrix all_theta, where the i-th row of all_theta </span>
<span class="hljs-comment">%corresponds to the classifier for label i</span>
<span class="hljs-comment">%   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels</span>
<span class="hljs-comment">%   logistic regression classifiers and returns each of these classifiers</span>
<span class="hljs-comment">%   in a matrix all_theta, where the i-th row of all_theta corresponds </span>
<span class="hljs-comment">%   to the classifier for label i</span>

<span class="hljs-comment">% Some useful variables</span>
m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);
n = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">2</span>);

<span class="hljs-comment">% You need to return the following variables correctly </span>
all_theta = <span class="hljs-built_in">zeros</span>(num_labels, n + <span class="hljs-number">1</span>);

<span class="hljs-comment">% Add ones to the X data matrix</span>
X = <span class="hljs-matrix">[ones(m, <span class="hljs-number">1</span>) X]</span>;

<span class="hljs-comment">% ====================== YOUR CODE HERE ======================</span>
<span class="hljs-comment">% Instructions: You should complete the following code to train num_labels</span>
<span class="hljs-comment">%               logistic regression classifiers with regularization</span>
<span class="hljs-comment">%               parameter lambda. </span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Hint: theta(:) will return a column vector.</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Hint: You can use y == c to obtain a vector of 1's and 0's that tell you</span>
<span class="hljs-comment">%       whether the ground truth is true/false for this class.</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Note: For this assignment, we recommend using fmincg to optimize the cost</span>
<span class="hljs-comment">%       function. It is okay to use a for-loop (for c = 1:num_labels) to</span>
<span class="hljs-comment">%       loop over the different classes.</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%       fmincg works similarly to fminunc, but is more efficient when we</span>
<span class="hljs-comment">%       are dealing with large number of parameters.</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Example Code for fmincg:</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%     % Set Initial theta</span>
<span class="hljs-comment">%     initial_theta = zeros(n + 1, 1);</span>
<span class="hljs-comment">%     </span>
<span class="hljs-comment">%     % Set options for fminunc</span>
<span class="hljs-comment">%     options = optimset('GradObj', 'on', 'MaxIter', 50);</span>
<span class="hljs-comment">% </span>
<span class="hljs-comment">%     % Run fmincg to obtain the optimal theta</span>
<span class="hljs-comment">%     % This function will return theta and the cost </span>
<span class="hljs-comment">%     [theta] = ...</span>
<span class="hljs-comment">%         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</span>
<span class="hljs-comment">%                 initial_theta, options);</span>
<span class="hljs-comment">%</span>

initial_theta = <span class="hljs-built_in">zeros</span>(n+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>);
options = optimset(<span class="hljs-string">'GradObj'</span>, <span class="hljs-string">'on'</span>, <span class="hljs-string">'MaxIter'</span>, <span class="hljs-number">50</span>);
<span class="hljs-keyword">for</span> c=<span class="hljs-number">1</span>:num_labels
    all_theta(c, :) = fmincg(@(t)(lrCostFunction(t, X, (y==c), lambda)), initial_theta, options);
<span class="hljs-keyword">end</span>
<span class="hljs-comment">% =========================================================================</span>
<span class="hljs-keyword">end</span>
</code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li style="color: rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li style="color: rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li style="color: rgb(153, 153, 153);">59</li></ul></pre>

<p>predictOneVsAll.m</p>



<pre class="prettyprint"><code class="language-matlab hljs  has-numbering"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">p</span> = <span class="hljs-title">predictOneVsAll</span><span class="hljs-params">(all_theta, X)</span></span>
<span class="hljs-comment">%PREDICT Predict the label for a trained one-vs-all classifier. The labels </span>
<span class="hljs-comment">%are in the range 1..K, where K = size(all_theta, 1). </span>
<span class="hljs-comment">%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions</span>
<span class="hljs-comment">%  for each example in the matrix X. Note that X contains the examples in</span>
<span class="hljs-comment">%  rows. all_theta is a matrix where the i-th row is a trained logistic</span>
<span class="hljs-comment">%  regression theta vector for the i-th class. You should set p to a vector</span>
<span class="hljs-comment">%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2</span>
<span class="hljs-comment">%  for 4 examples) </span>

m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);
num_labels = <span class="hljs-built_in">size</span>(all_theta, <span class="hljs-number">1</span>);

<span class="hljs-comment">% You need to return the following variables correctly </span>
p = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>), <span class="hljs-number">1</span>);

<span class="hljs-comment">% Add ones to the X data matrix</span>
X = <span class="hljs-matrix">[ones(m, <span class="hljs-number">1</span>) X]</span>;

<span class="hljs-comment">% ====================== YOUR CODE HERE ======================</span>
<span class="hljs-comment">% Instructions: Complete the following code to make predictions using</span>
<span class="hljs-comment">%               your learned logistic regression parameters (one-vs-all).</span>
<span class="hljs-comment">%               You should set p to a vector of predictions (from 1 to</span>
<span class="hljs-comment">%               num_labels).</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Hint: This code can be done all vectorized using the max function.</span>
<span class="hljs-comment">%       In particular, the max function can also return the index of the </span>
<span class="hljs-comment">%       max element, for more information see 'help max'. If your examples </span>
<span class="hljs-comment">%       are in rows, then, you can use max(A, [], 2) to obtain the max </span>
<span class="hljs-comment">%       for each row.</span>
<span class="hljs-comment">%       </span>

temp = all_theta * <span class="hljs-transposed_variable">X'</span>;
<span class="hljs-matrix">[maxx, pp]</span> = max(temp);
p = <span class="hljs-transposed_variable">pp'</span>;
<span class="hljs-comment">% =========================================================================</span>
<span class="hljs-keyword">end</span>
</code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li></ul></pre>

<p><img src="https://img-blog.csdn.net/20170502221409516?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
最终预测准确性：Training Set Accuracy: 95.120000</p>

<p>下面是以三层bp神经网络处理的手写数字识别，其中权重矩阵已给出，故少了反向传播的步骤。 <br>
ex3_nn.m</p>



<pre class="prettyprint"><code class="language-matlab hljs  has-numbering"><span class="hljs-comment">%% Machine Learning Online Class - Exercise 3 | Part 2: Neural Networks</span>

<span class="hljs-comment">%  Instructions</span>
<span class="hljs-comment">%  ------------</span>
<span class="hljs-comment">% </span>
<span class="hljs-comment">%  This file contains code that helps you get started on the</span>
<span class="hljs-comment">%  linear exercise. You will need to complete the following functions </span>
<span class="hljs-comment">%  in this exericse:</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%     lrCostFunction.m (logistic regression cost function)</span>
<span class="hljs-comment">%     oneVsAll.m</span>
<span class="hljs-comment">%     predictOneVsAll.m</span>
<span class="hljs-comment">%     predict.m</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">%  For this exercise, you will not need to change any code in this file,</span>
<span class="hljs-comment">%  or any other files other than those mentioned above.</span>
<span class="hljs-comment">%</span>

<span class="hljs-comment">%% Initialization</span>
clear ; close all; clc

<span class="hljs-comment">%% Setup the parameters you will use for this exercise</span>
input_layer_size  = <span class="hljs-number">400</span>;  <span class="hljs-comment">% 20x20 Input Images of Digits</span>
hidden_layer_size = <span class="hljs-number">25</span>;   <span class="hljs-comment">% 25 hidden units</span>
num_labels = <span class="hljs-number">10</span>;          <span class="hljs-comment">% 10 labels, from 1 to 10   </span>
                          <span class="hljs-comment">% (note that we have mapped "0" to label 10)</span>

<span class="hljs-comment">%% =========== Part 1: Loading and Visualizing Data =============</span>
<span class="hljs-comment">%  We start the exercise by first loading and visualizing the dataset. </span>
<span class="hljs-comment">%  You will be working with a dataset that contains handwritten digits.</span>
<span class="hljs-comment">%</span>

<span class="hljs-comment">% Load Training Data</span>
fprintf(<span class="hljs-string">'Loading and Visualizing Data ...\n'</span>)

load(<span class="hljs-string">'ex3data1.mat'</span>);
m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);

<span class="hljs-comment">% Randomly select 100 data points to display</span>
sel = randperm(<span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>));
sel = sel(<span class="hljs-number">1</span>:<span class="hljs-number">100</span>);

displayData(X(sel, :));

fprintf(<span class="hljs-string">'Program paused. Press enter to continue.\n'</span>);
pause;

<span class="hljs-comment">%% ================ Part 2: Loading Pameters ================</span>
<span class="hljs-comment">% In this part of the exercise, we load some pre-initialized </span>
<span class="hljs-comment">% neural network parameters.</span>

fprintf(<span class="hljs-string">'\nLoading Saved Neural Network Parameters ...\n'</span>)

<span class="hljs-comment">% Load the weights into variables Theta1 and Theta2</span>
load(<span class="hljs-string">'ex3weights.mat'</span>);

<span class="hljs-comment">%% ================= Part 3: Implement Predict =================</span>
<span class="hljs-comment">%  After training the neural network, we would like to use it to predict</span>
<span class="hljs-comment">%  the labels. You will now implement the "predict" function to use the</span>
<span class="hljs-comment">%  neural network to predict the labels of the training set. This lets</span>
<span class="hljs-comment">%  you compute the training set accuracy.</span>

pred = predict(Theta1, Theta2, X);

fprintf(<span class="hljs-string">'\nTraining Set Accuracy: %f\n'</span>, mean(double(pred == y)) * <span class="hljs-number">100</span>);

fprintf(<span class="hljs-string">'Program paused. Press enter to continue.\n'</span>);
pause;

<span class="hljs-comment">%  To give you an idea of the network's output, you can also run</span>
<span class="hljs-comment">%  through the examples one at the a time to see what it is predicting.</span>

<span class="hljs-comment">%  Randomly permute examples</span>
rp = randperm(m);

<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:m
    <span class="hljs-comment">% Display </span>
    fprintf(<span class="hljs-string">'\nDisplaying Example Image\n'</span>);
    displayData(X(rp(<span class="hljs-built_in">i</span>), :));

    pred = predict(Theta1, Theta2, X(rp(<span class="hljs-built_in">i</span>),:));
    fprintf(<span class="hljs-string">'\nNeural Network Prediction: %d (digit %d)\n'</span>, pred, <span class="hljs-built_in">mod</span>(pred, <span class="hljs-number">10</span>));

    <span class="hljs-comment">% Pause with quit option</span>
    s = input(<span class="hljs-string">'Paused - press enter to continue, q to exit:'</span>,<span class="hljs-string">'s'</span>);
    <span class="hljs-keyword">if</span> s == <span class="hljs-string">'q'</span>
      <span class="hljs-keyword">break</span>
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li style="color: rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li style="color: rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li style="color: rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li style="color: rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li style="color: rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li style="color: rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, 153);">73</li><li style="color: rgb(153, 153, 153);">74</li><li style="color: rgb(153, 153, 153);">75</li><li style="color: rgb(153, 153, 153);">76</li><li style="color: rgb(153, 153, 153);">77</li><li style="color: rgb(153, 153, 153);">78</li><li style="color: rgb(153, 153, 153);">79</li><li style="color: rgb(153, 153, 153);">80</li><li style="color: rgb(153, 153, 153);">81</li><li style="color: rgb(153, 153, 153);">82</li><li style="color: rgb(153, 153, 153);">83</li><li style="color: rgb(153, 153, 153);">84</li><li style="color: rgb(153, 153, 153);">85</li><li style="color: rgb(153, 153, 153);">86</li><li style="color: rgb(153, 153, 153);">87</li><li style="color: rgb(153, 153, 153);">88</li><li style="color: rgb(153, 153, 153);">89</li></ul></pre>

<p>predict.m</p>



<pre class="prettyprint"><code class="language-matlab hljs  has-numbering"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">p</span> = <span class="hljs-title">predict</span><span class="hljs-params">(Theta1, Theta2, X)</span></span>
<span class="hljs-comment">%PREDICT Predict the label of an input given a trained neural network</span>
<span class="hljs-comment">%   p = PREDICT(Theta1, Theta2, X) outputs the predicted label of X given the</span>
<span class="hljs-comment">%   trained weights of a neural network (Theta1, Theta2)</span>

<span class="hljs-comment">% Useful values</span>
m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);
num_labels = <span class="hljs-built_in">size</span>(Theta2, <span class="hljs-number">1</span>);

<span class="hljs-comment">% You need to return the following variables correctly </span>
p = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>), <span class="hljs-number">1</span>);

<span class="hljs-comment">% ====================== YOUR CODE HERE ======================</span>
<span class="hljs-comment">% Instructions: Complete the following code to make predictions using</span>
<span class="hljs-comment">%               your learned neural network. You should set p to a </span>
<span class="hljs-comment">%               vector containing labels between 1 to num_labels.</span>
<span class="hljs-comment">%</span>
<span class="hljs-comment">% Hint: The max function might come in useful. In particular, the max</span>
<span class="hljs-comment">%       function can also return the index of the max element, for more</span>
<span class="hljs-comment">%       information see 'help max'. If your examples are in rows, then, you</span>
<span class="hljs-comment">%       can use max(A, [], 2) to obtain the max for each row.</span>
<span class="hljs-comment">%</span>
X = <span class="hljs-matrix">[ones(m, <span class="hljs-number">1</span>) X]</span>;
XX = sigmoid(X*<span class="hljs-transposed_variable">Theta1'</span>);
pp = sigmoid(<span class="hljs-matrix">[ones(size(XX, <span class="hljs-number">1</span>), <span class="hljs-number">1</span>) XX]</span> * <span class="hljs-transposed_variable">Theta2'</span>);
<span class="hljs-matrix">[a, p]</span> = max(pp, <span class="hljs-matrix">[]</span>, <span class="hljs-number">2</span>);
<span class="hljs-comment">% =========================================================================</span>
<span class="hljs-keyword">end</span></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li></ul></pre>

<p><img src="https://img-blog.csdn.net/20170502222438730?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br>
<img src="https://img-blog.csdn.net/20170502222454078?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p>

<p>最终预测准确性：Training Set Accuracy: 97.520000</p>                